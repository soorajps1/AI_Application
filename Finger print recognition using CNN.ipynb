{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7a4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\user\\AppData\\Roaming\\Python\\Python311\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import layers, regularizers, optimizers, callbacks\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5c982225",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 96\n",
    "\n",
    "def load_data(path, train=True):\n",
    "    print(\"Loading data from: \", path)\n",
    "    data = []\n",
    "    for img in os.listdir(path):\n",
    "        imgname, ext = os.path.splitext(img)\n",
    "        ID, etc = imgname.split('__')\n",
    "        ID = int(ID) - 1 # to_categorical encodes starting from 0\n",
    "        if train:\n",
    "            _, lr, finger, _, _ = etc.split('_')\n",
    "        else:\n",
    "            _, lr, finger, _  = etc.split('_')\n",
    "        if lr=='Left':\n",
    "            base = 0 # left hand corresponding to 0-4\n",
    "        else: base  = 5 # right hand corresponding to 5-9\n",
    "        if finger==\"little\":\n",
    "            fingerNum = base + 0\n",
    "        elif finger=='ring':\n",
    "            fingerNum = base + 1\n",
    "        elif finger=='middle':\n",
    "            fingerNum = base + 2\n",
    "        elif finger=='index':\n",
    "            fingerNum = base + 3 \n",
    "        else: fingerNum = base + 4\n",
    "        img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_GRAYSCALE)\n",
    "        img_resize = cv2.resize(img_array, (img_size, img_size))\n",
    "        data.append([ID, fingerNum, img_resize])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1298a0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from:  D:/Dataset/SOCOFing/Altered/Altered-Easy\n",
      "Loading data from:  D:/Dataset/SOCOFing/Altered/Altered-Medium\n",
      "Loading data from:  D:/Dataset/SOCOFing/Altered/Altered-Hard\n",
      "Loading data from:  D:/Dataset/SOCOFing/Real\n",
      "Shapes of individual datasets:\n",
      "Easy_data shape: Not available\n",
      "Medium_data shape: Not available\n",
      "Hard_data shape: Not available\n",
      "Real_data shape: Not available\n",
      "Error during concatenation: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (17931, 3) + inhomogeneous part.\n"
     ]
    }
   ],
   "source": [
    "Altered_path = \"D:/Dataset/SOCOFing/Altered/Altered-\"\n",
    "Real_path = \"D:/Dataset/SOCOFing/Real\"\n",
    "\n",
    "# Load data\n",
    "Easy_data = load_data(Altered_path + 'Easy', train=True)\n",
    "Medium_data = load_data(Altered_path + 'Medium', train=True)\n",
    "Hard_data = load_data(Altered_path + 'Hard', train=True)\n",
    "Real_data = load_data(Real_path, train=False)\n",
    "\n",
    "# Check shapes of individual datasets\n",
    "print(\"Shapes of individual datasets:\")\n",
    "print(\"Easy_data shape:\", Easy_data.shape if hasattr(Easy_data, 'shape') else \"Not available\")\n",
    "print(\"Medium_data shape:\", Medium_data.shape if hasattr(Medium_data, 'shape') else \"Not available\")\n",
    "print(\"Hard_data shape:\", Hard_data.shape if hasattr(Hard_data, 'shape') else \"Not available\")\n",
    "print(\"Real_data shape:\", Real_data.shape if hasattr(Real_data, 'shape') else \"Not available\")\n",
    "\n",
    "# Concatenate data\n",
    "try:\n",
    "    Altered_data = np.concatenate([Easy_data, Medium_data, Hard_data], axis=0)\n",
    "    del Easy_data, Medium_data, Hard_data\n",
    "    print(\"Concatenation successful. Altered_data shape:\", Altered_data.shape)\n",
    "except ValueError as e:\n",
    "    print(\"Error during concatenation:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acebd28a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Altered_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m X_Altered, y_SubjectID_Altered, y_fingerNum_Altered \u001b[38;5;241m=\u001b[39m [], [], []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m SubjectID, fingerNum, feature \u001b[38;5;129;01min\u001b[39;00m Altered_data:\n\u001b[0;32m      4\u001b[0m     X_Altered\u001b[38;5;241m.\u001b[39mappend(feature)\n\u001b[0;32m      5\u001b[0m     y_SubjectID_Altered\u001b[38;5;241m.\u001b[39mappend(SubjectID)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Altered_data' is not defined"
     ]
    }
   ],
   "source": [
    "X_Altered, y_SubjectID_Altered, y_fingerNum_Altered = [], [], []\n",
    "\n",
    "for SubjectID, fingerNum, feature in Altered_data:\n",
    "    X_Altered.append(feature)\n",
    "    y_SubjectID_Altered.append(SubjectID)\n",
    "    y_fingerNum_Altered.append(fingerNum)\n",
    "\n",
    "X_Altered = np.array(X_Altered).reshape(-1, img_size, img_size, 1)\n",
    "X_Altered = X_Altered / 255.0 # Normalize to [0, 1]\n",
    "y_SubjectID_Altered = to_categorical(y_SubjectID_Altered, num_classes=600) # 600 persons in total\n",
    "y_fingerNum_Altered = to_categorical(y_fingerNum_Altered, num_classes=10) # 10 fingers per person\n",
    "\n",
    "X_SubjectID_train, X_SubjectID_val, y_SubjectID_train, y_SubjectID_val = train_test_split(\n",
    "    X_Altered, y_SubjectID_Altered, test_size=0.2, random_state=2)\n",
    "X_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val = train_test_split(\n",
    "    X_Altered, y_fingerNum_Altered, test_size=0.2, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bf5ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_SubjectID_test, y_fingerNum_test = [], [], []\n",
    "\n",
    "for SubjectID, fingerNum, feature in Real_data:\n",
    "    X_test.append(feature)\n",
    "    y_SubjectID_test.append(SubjectID)\n",
    "    y_fingerNum_test.append(fingerNum)\n",
    "\n",
    "X_test = np.array(X_test).reshape(-1, img_size, img_size, 1)\n",
    "X_test = X_test / 255.0\n",
    "\n",
    "y_SubjectID_test = to_categorical(y_SubjectID_test, num_classes=600)\n",
    "y_fingerNum_test = to_categorical(y_fingerNum_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2d797",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shapes:                  Feature shape    label shape\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"full SubjectID data:  \", X_Altered.shape, y_SubjectID_Altered.shape)\n",
    "print(\"SubjectID_Train:      \", X_SubjectID_train.shape, y_SubjectID_train.shape)\n",
    "print(\"SubjectID_Validation: \", X_SubjectID_val.shape, y_SubjectID_val.shape)\n",
    "print(\"SubjectID_Test:       \", X_test.shape, y_SubjectID_test.shape)\n",
    "print(\"----------------------------------------------------\")\n",
    "print(\"full fingerNum data:  \", X_Altered.shape, y_fingerNum_Altered.shape)\n",
    "print(\"fingerNum_Train:      \", X_fingerNum_train.shape, y_fingerNum_train.shape)\n",
    "print(\"fingerNum_Validation: \", X_fingerNum_val.shape, y_fingerNum_val.shape)\n",
    "print(\"fingerNum_Test:       \", X_test.shape, y_fingerNum_test.shape)\n",
    "\n",
    "del Altered_data, Real_data, y_SubjectID_Altered # Free some memory again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dded7910",
   "metadata": {},
   "outputs": [],
   "source": [
    "nets = 2\n",
    "model = [0] * nets\n",
    "final_Dense_units = [600, 10]\n",
    "model_name = ['SubjectID_Mod', 'FingerNum_Mod']\n",
    "for i in range(nets):\n",
    "    model[i] = Sequential(name=model_name[i])\n",
    "\n",
    "    model[i].add(layers.Conv2D(32, (5, 5), activation='relu', kernel_regularizer=regularizers.l2(0.001), input_shape = (96, 96, 1)))\n",
    "    model[i].add(layers.BatchNormalization())\n",
    "    model[i].add(layers.MaxPool2D((2, 2)))\n",
    "    model[i].add(layers.Conv2D(64,(5, 5), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model[i].add(layers.BatchNormalization())\n",
    "    model[i].add(layers.MaxPool2D((2, 2)))\n",
    "    model[i].add(layers.Conv2D(128,(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model[i].add(layers.BatchNormalization())\n",
    "    model[i].add(layers.MaxPool2D((2, 2)))\n",
    "    model[i].add(layers.Dropout(0.3))\n",
    "    model[i].add(layers.Flatten())\n",
    "    model[i].add(layers.Dense(256, activation='relu'))\n",
    "    model[i].add(layers.Dropout(0.4))\n",
    "    model[i].add(layers.Dense(final_Dense_units[i], activation='softmax'))\n",
    "\n",
    "    # Complete with Adam optimizer and entropy cost\n",
    "    model[i].compile(optimizer=optimizers.Adam(learning_rate=0.0001), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model[i].summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde2e645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot Id model graph in layers\n",
    "plot_model(model[0], show_shapes=True, to_file='./model0.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cc10e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot finger model grapy in layers\n",
    "plot_model(model[1], show_shapes=True, to_file='./model1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ca999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because of the RAM limitatiaon(Max 13GB), two dataset will cause overloaded problem\n",
    "# Thus no enougth remaining RAM for models fitting\n",
    "# So I delete the fingerNum dataset before the SubjectID model fitting, then reload it when needed.\n",
    "del X_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc48a392",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = [0] * nets\n",
    "CallBack = [0] * nets\n",
    "ReduceLR_minlr = [1e-9, 1e-7]\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "for i in range(nets):\n",
    "    CallBack[i] = [\n",
    "        callbacks.EarlyStopping(monitor='val_accuracy', patience=10, mode='max', verbose=1),\n",
    "        callbacks.ReduceLROnPlateau(factor=0.1, patience=1, min_lr=ReduceLR_minlr[i], verbose=1),\n",
    "        callbacks.TensorBoard(log_dir=\"./log_dir/\"+model_name[i])]\n",
    "history[0] = model[0].fit(X_SubjectID_train, y_SubjectID_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs, \n",
    "                    validation_data = (X_SubjectID_val, y_SubjectID_val),\n",
    "                    verbose = 1, callbacks= CallBack[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad1d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the SubjectID dataset after it was used\n",
    "del X_SubjectID_train, X_SubjectID_val, y_SubjectID_train, y_SubjectID_val\n",
    "# Then reload fingerNum dataset before model fitting\n",
    "X_fingerNum_train, X_fingerNum_val, y_fingerNum_train, y_fingerNum_val = train_test_split(\n",
    "    X_Altered, y_fingerNum_Altered, test_size=0.2, random_state=2)\n",
    "\n",
    "del X_Altered, y_fingerNum_Altered\n",
    "\n",
    "history[1] = model[1].fit(X_fingerNum_train, y_fingerNum_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs, \n",
    "                    validation_data = (X_fingerNum_val, y_fingerNum_val),\n",
    "                    verbose = 1, callbacks= CallBack[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c2e72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "# Launch TensorBoard\n",
    "# Supervising the SubjectID model\n",
    "%tensorboard --logdir './log_dir/SubjectID_log'\n",
    "# or, supervising the fingerNum model\n",
    "# %tensorboard --logdir './log_dir/fingerNum_log'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a803f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = [0] * nets\n",
    "val_acc = [0] * nets\n",
    "loss = [0] * nets\n",
    "val_loss = [0] * nets\n",
    "for i in range(nets):\n",
    "    acc[i] = history[i].history['accuracy']\n",
    "    val_acc[i] = history[i].history['val_accuracy']\n",
    "    loss[i] = history[i].history['loss']\n",
    "    val_loss[i] = history[i].history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc[i]) + 1)\n",
    "    # plot figures models\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, acc[i], label='Training acc of '+model_name[i])\n",
    "    plt.plot(epochs, val_acc[i], label='Validation acc of '+model_name[i])\n",
    "    plt.title('Training and validation accuracy of '+model_name[i])\n",
    "    plt.legend()\n",
    "    plt.figure()\n",
    "    plt.plot(epochs, loss[i],  label='Training loss of '+model_name[i])\n",
    "    plt.plot(epochs, val_loss[i], label='Validation loss of '+model_name[i])\n",
    "    plt.title('Training and validation loss of '+model_name[i])\n",
    "    plt.legend()\n",
    "\n",
    "testing_acc_Id = model[0].evaluate([X_test], [y_SubjectID_test], verbose=0)\n",
    "print(\"Id recognition accuracy: \",testing_acc_Id[1]*100, \"%\")\n",
    "testing_acc_finger = model[1].evaluate([X_test], [y_fingerNum_test], verbose=0)\n",
    "print(\"Finger recognition accuracy: \",testing_acc_finger[1]*100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007a5ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize finger prediction with confusion matrix \n",
    "def plot_confusion_matrix(conmat, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(conmat, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        conmat = conmat.astype('float') / conmat.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    thresh = conmat.max() / 2.\n",
    "    for i, j in itertools.product(range(conmat.shape[0]), range(conmat.shape[1])):\n",
    "        plt.text(j, i, conmat[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if conmat[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('Real label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "# Predict the values from the test dataset\n",
    "y_fingerNum_pred = model[1].predict(X_test)\n",
    "# Convert predictions classes to one hot vectors \n",
    "y_fingerNum_pred_classes = np.argmax(y_fingerNum_pred, axis=1) \n",
    "# Convert test observations to one hot vectors\n",
    "y_fingerNum_real = np.argmax(y_fingerNum_test, axis=1) \n",
    "# compute the confusion matrix\n",
    "confusion_mtx = confusion_matrix(y_fingerNum_real, y_fingerNum_pred_classes) \n",
    "# plot the confusion matrix\n",
    "plot_confusion_matrix(confusion_mtx, classes = range(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf608bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_fingername(fingernum):\n",
    "    if fingernum>=5:\n",
    "        fingername = \"right \"\n",
    "        fingernum -= 5\n",
    "    else: fingername = \"left \"\n",
    "    if fingernum==0:\n",
    "        fingername += \"little\"\n",
    "    elif fingernum==1:\n",
    "        fingername += \"ring\"\n",
    "    elif fingernum==2:\n",
    "        fingername += \"middle\"\n",
    "    elif fingernum==3:\n",
    "        fingername += \"index\"\n",
    "    else: fingername += \"thumb\"\n",
    "    return fingername\n",
    "\n",
    "# Randomly pick a fingerprint from test data to predict both its Id and fingername\n",
    "rand_fp_num = random.randint(0, X_test.shape[0]-1)\n",
    "plt.imshow(X_test[rand_fp_num].reshape((96, 96)), cmap ='gray')\n",
    "y_SubjectID_pred = model[0].predict(X_test)\n",
    "Id_pred = np.argmax(y_SubjectID_pred[rand_fp_num])\n",
    "Id_real = np.argmax(y_SubjectID_test[rand_fp_num])\n",
    "fingerNum_pred = np.argmax(y_fingerNum_pred[rand_fp_num])\n",
    "fingerNum_real = np.argmax(y_fingerNum_test[rand_fp_num])\n",
    "if Id_pred==Id_real and fingerNum_pred==fingerNum_real:\n",
    "    print(\"Infomation confirm! Fingerprint matches: person Id\",Id_pred, show_fingername(fingerNum_pred))\n",
    "else:\n",
    "    print(\"Oops! Prediction is wrong!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
